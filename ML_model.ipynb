{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import struct\n",
    "from haversine import haversine, Unit\n",
    "from math import sqrt\n",
    "from scipy.signal import medfilt\n",
    "from datetime import datetime, timedelta\n",
    "from timezonefinder import TimezoneFinder\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "MAX_MEMORY = '5g'\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"FitRec\") \\\n",
    "        .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "        .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- altitude: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- heart_rate: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- latitude: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- longitude: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- speed: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- sport: string (nullable = true)\n",
      " |-- timestamp: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.json('endomondoHR_proper.json')\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167783"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the outliner\n",
    "# Take sample from male and female that have class balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[128] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data.rdd.sample(False, 200, 123)\n",
    "sample = sample.filter(lambda x: all(heart_rate > 40 for heart_rate in x.heart_rate))\n",
    "sample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167010"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(timestamp, long, lat):\n",
    "    utc_time = datetime.fromtimestamp(timestamp)\n",
    "#     tf = TimezoneFinder()\n",
    "#     timezone = tf.timezone_at(lng=long, lat=lat)\n",
    "#     try:\n",
    "#         offset = pytz.timezone(timezone).utcoffset(utc_time)\n",
    "#     except:\n",
    "#         offset = timedelta(hours=0)\n",
    "    true_time = utc_time - timedelta(hours=7)\n",
    "    return true_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_feature(row):\n",
    "    \"\"\"\n",
    "    Calculate distance\n",
    "    \"\"\"\n",
    "    lat = medfilt(row.latitude, 3).tolist()\n",
    "    long = medfilt(row.longitude, 3).tolist()\n",
    "    \n",
    "    alt = [0.0001893939*i for i in row.altitude] #Convert from ft to mile\n",
    "    indices = range(1,len(lat))\n",
    "    \n",
    "    diff_alt = [0.0]\n",
    "    diff_alt += [alt[i] - alt[i-1] for i in indices] \n",
    "    \n",
    "    diff_time = [0.0]\n",
    "    diff_time += [row.timestamp[i] - row.timestamp[i-1] for i in indices]\n",
    "    \n",
    "    #Calculate different of heart rate between 2 consecutive timestamp\n",
    "    diff_heart = [0.0]\n",
    "    diff_heart += [row.heart_rate[i] - row.heart_rate[i-1] for i in indices]\n",
    "    \n",
    "    #Calculate distance derive between 2 consecutive timestamps.\n",
    "    #Unit: mile\n",
    "    distance = [0.0]\n",
    "    distance += [haversine((lat[i-1],long[i-1]), (lat[i], long[i]), unit=Unit.MILES) for i in indices]\n",
    "    d_distance = [sqrt(d**2 + a**2) for d, a in zip(distance, diff_alt)] #approximate \n",
    "    \n",
    "    #Calculate average derived speed between 2 consecutive timestamps.\n",
    "    #Unit: MPH\n",
    "    d_speed = [0.0]\n",
    "    try:\n",
    "        d_speed += [dist/time*3600 for dist, time in zip(d_distance[1:], diff_time[1:])]\n",
    "    except:\n",
    "        d_speed = [0.0] * len(row.timestamp)\n",
    "        \n",
    "    #Get local hours\n",
    "    hours = []\n",
    "    minutes = []\n",
    "    for (lg, lt, ts) in zip(row.longitude, row.latitude, row.timestamp):\n",
    "        local_time = get_time(ts,lg,lt)\n",
    "        hours.append(local_time.hour)\n",
    "        minutes.append(local_time.minute)\n",
    "    return Row(altitude = row.altitude,\\\n",
    "               gender = row.gender,\\\n",
    "               heart_rate = row.heart_rate,\\\n",
    "               id = row.id,\\\n",
    "               latitude = row.latitude,\\\n",
    "               longitude = row.longitude,\\\n",
    "               speed = row.speed,\\\n",
    "               sport = row.sport,\\\n",
    "               timestamp = row.timestamp,\\\n",
    "               url = row.url,\\\n",
    "               userId = row.userId,\\\n",
    "               distance = d_distance,\\\n",
    "               derive_speed = d_speed,\\\n",
    "               diff_time = diff_time,\\\n",
    "               diff_heart_rate = diff_heart,\\\n",
    "               hours = hours,\\\n",
    "               minutes = minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(row, lag=2):\n",
    "    \"\"\"\n",
    "    Transform a workout session to multiples window frames.\n",
    "    \"\"\"\n",
    "    prefix = [row.id, row.url, row.userId, row.sport, row.gender]\n",
    "    flatted = []\n",
    "    speed = row.speed if row.speed is not None else row.derive_speed\n",
    "    a_features = [row.longitude, row.latitude, row.hours]\n",
    "    b_features = [speed, row.distance, row.diff_time]\n",
    "    c_features = [row.heart_rate, row.diff_heart_rate]\n",
    "    for idx in range(len(row.timestamp)):\n",
    "        a_row = []\n",
    "        b_row = []\n",
    "        c_row = []\n",
    "        if idx < lag:\n",
    "            mask = [0.0] * (lag-idx) #[0, 0, 1]\n",
    "            for a in a_features:\n",
    "                a_row += mask + a[0:idx+1]\n",
    "            for b in b_features:\n",
    "                roller = mask + b[0:idx+1]\n",
    "                b_row += roller + [float(np.min(roller)), float(np.max(roller)), float(np.mean(roller)),\\\n",
    "                          float(np.std(roller))]\n",
    "            for c in c_features:\n",
    "                roller = mask + c[0:idx+1]\n",
    "                b_row += roller + [float(np.min(roller[:-1])), float(np.max(roller[:-1])), \\\n",
    "                                   float(np.mean(roller[:-1])), float(np.std(roller[:-1]))]\n",
    "        else:\n",
    "            for a in a_features:\n",
    "                a_row += a[idx-lag:idx+1]\n",
    "            for b in b_features:\n",
    "                roller = b[idx-lag:idx+1]\n",
    "#                 print(len(roller), idx)\n",
    "                b_row += roller + [float(np.min(roller)), float(np.max(roller)), float(np.mean(roller)),\\\n",
    "                          float(np.std(roller))]\n",
    "            for c in c_features:\n",
    "                roller = c[idx-lag:idx+1]\n",
    "                c_row += roller + [float(np.min(roller[:-1])), float(np.max(roller[:-1])), \\\n",
    "                                   float(np.mean(roller[:-1])), float(np.std(roller[:-1]))]\n",
    "                \n",
    "#         if len(prefix) + len(a_row) + len(b_row) + len(c_row) != 49:\n",
    "#             print(prefix, len(prefix))\n",
    "#             print(a_row, len(a_row))\n",
    "#             print(b_row, len(b_row))\n",
    "#             print(c_row, len(c_row))\n",
    "#             continue\n",
    "        tmp = a_row + b_row + c_row\n",
    "        tmp = [float(x) for x in a_row + b_row + c_row]\n",
    "        flatted.append(prefix + tmp)\n",
    "#         assert len(prefix) == 5\n",
    "#         assert len(a_row) == 16, print(a_row)\n",
    "#         assert len(b_row) == 35, print(b_row)\n",
    "#         for x in prefix + a_row + b_row + c_row:\n",
    "#             if x is None:\n",
    "#                 print('aaa')\n",
    "    return flatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'url', 'userId', 'sport', 'gender', 'longitude_2', 'longitude_1', 'longitude_0', 'latitude_2', 'latitude_1', 'latitude_0', 'hours_2', 'hours_1', 'hours_0', 'speed_2', 'speed_1', 'speed_0', 'speed_min', 'speed_max', 'speed_mean', 'speed_std', 'distance_2', 'distance_1', 'distance_0', 'distance_min', 'distance_max', 'distance_mean', 'distance_std', 'diff_time_2', 'diff_time_1', 'diff_time_0', 'diff_time_min', 'diff_time_max', 'diff_time_mean', 'diff_time_std', 'heart_rate_2', 'heart_rate_1', 'heart_rate_0', 'heart_rate_min', 'heart_rate_max', 'heart_rate_mean', 'heart_rate_std', 'diff_heart_rate_2', 'diff_heart_rate_1', 'diff_heart_rate_0', 'diff_heart_rate_min', 'diff_heart_rate_max', 'diff_heart_rate_mean', 'diff_heart_rate_std']\n"
     ]
    }
   ],
   "source": [
    "agg_name = ['min', 'max', 'mean', 'std']\n",
    "a_name = ['longitude', 'latitude', 'hours']\n",
    "b_name = ['speed', 'distance', 'diff_time', 'heart_rate', 'diff_heart_rate']\n",
    "column = ['id', 'url', 'userId', 'sport', 'gender']\n",
    "\n",
    "for name in a_name:\n",
    "    column += [name + '_{}'.format(i) for i in range(2, -1, -1)]\n",
    "for name in b_name:\n",
    "    column += [name + '_{}'.format(i) for i in range(2, -1, -1)]\n",
    "    column += [name + '_{}'.format(i) for i in agg_name]\n",
    "print(column)\n",
    "#export feature importances\n",
    "# 2 rounds of training:\n",
    "#first: basic model => feature importances\n",
    "#second round: importances features => train a model => better performance\n",
    "\n",
    "#square(heart_rate), heart_rate^3, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sample.map(derive_feature).flatMap(transform).toDF(column)\n",
    "category_cols = ['sport', 'gender']\n",
    "\n",
    "stages =[]\n",
    "for category_col in category_cols:\n",
    "    str_indexer = StringIndexer(inputCol = category_col, outputCol = category_col + '_index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[str_indexer.getOutputCol()]\\\n",
    "                                     , outputCols=[category_col + \"_vec\"])\n",
    "    stages += [str_indexer, encoder]\n",
    "numeric_cols = [x for x in column[5:] if x != 'diff_heart_rate_0' and x != 'heart_rate_0']\n",
    "assembler_input = [c + \"_vec\" for c in category_cols] + numeric_cols\n",
    "assembler = VectorAssembler(inputCols=assembler_input, outputCol='features', handleInvalid='skip')\n",
    "stages += [assembler]\n",
    "\n",
    "partial_pipeline = Pipeline().setStages(stages)\n",
    "pipeline_model = partial_pipeline.fit(df)\n",
    "prepared_df = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc = sample.map(derive_feature).flatMap(transform)\n",
    "# abc = sc.parallelize(abc.takeSample(False, 10)).toDF(column)\n",
    "# abc.show(10)\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.select('features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "# df.select('label').cast('str')\n",
    "# df.select('prediction').cast('integer')\n",
    "\n",
    "train, test = prepared_df.randomSplit([0.8, 0.2], seed=123)\n",
    "rf = RandomForestRegressor(labelCol=\"diff_heart_rate_0\", featuresCol=\"features\")\n",
    "rf_model = rf.fit(train)\n",
    "\n",
    "predict = rf_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(assembler_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_and_pred = predict.rdd.map(lambda x: (float(x.diff_heart_rate_0), float(x.prediction)))\n",
    "# ((real value, preditec value)) \n",
    "metrics = RegressionMetrics(value_and_pred)\n",
    "# Scale of heart rate from 60 - 200\n",
    "\n",
    "print(\"MSE = %s\" % metrics.meanSquaredError)\n",
    "print(\"RMSE = %s\" % metrics.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.select('prediction').show(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
